This directory contains all functions that may need to be used more
than once in our analysis.

<<>>=
f.plot_counts_alacarte<-function(vectorofgenes, countlist, condlist, ...) {
    for (i in 1:length(vectorofgenes)) {
	datatoplot<-countlist[ vectorofgenes[i], ]
	max_y<-max(datatoplot)
	plot.default( condlist,
             datatoplot, xlab = 'Condition', ylab = 'counts',
             ylim = c(0,max_y), main = vectorofgenes[i], xaxt = 'n', ...)
        axis(1, at = seq(along = levels(condlist) ),
             labels = levels( condlist ), las = 2 )
    }
}
@

\subsection{Running \deseq}

A helper function that will take two condition names, conduct the
differential expression test, and write the data to a file.
<<>>=
f.deseq_do_andwrite <- function(countdataset, condpair,
                                fileprefix ) {
    message( paste( 'Testing', condpair[1], 'vs', condpair[2]))
    nbinomresult <- nbinomTest(countdataset, condpair[1], condpair[2])
    filename <- paste0(fileprefix, condpair[1] , condpair[2])
    write.table( nbinomresult, file = filename, quote = FALSE, sep = '\t')
    return( list(condA = condpair[1], condB = condpair[2],
                 filename = filename))
}
@

Do all the pairwise tests, write the results to files, and make an index.
<<>>=
f.deseq_testallpairs <- function(countdataset, fileprefix ) {
    FUN = function (x)  f.deseq_do_andwrite(countdataset,x,fileprefix)
    nbinomindex<- apply(X = combn(levels(conditions(countdataset)),m=2),
                        MARGIN = 2, FUN = FUN)
    return(nbinomindex)
}
@

A function for retrieving a DESEQ test. \texttt{nindex} should be a
list of elements, each of which has elements \texttt{condA},
\texttt{condB}, and \texttt{filename}. If condA and condB are found
reversed in the nindex, then after loading the file, the foldchanges
are adjusted so that always the foldchange is for condB over condA.

<<>>=
f.loadntest<-function(condA,condB,nindex){
    ntable<-t(sapply(nindex,
                     FUN=function (x) c(paste0(x$condA,'.',x$condB),
                     x$filename)))
    forward.name<-paste0(condA,'.',condB)
    reverse.name<-paste0(condB,'.',condA)
    if (forward.name %in% ntable[,1] ) {
        dframe<-read.delim(ntable[match(forward.name,ntable[,1]),2])}
    else if (reverse.name %in% ntable[,1]) {
        dframe<-read.delim(ntable[match(reverse.name,ntable[,1]),2])
        dframe[,c('baseMeanA','baseMeanB')]<-
            dframe[,c('baseMeanB','baseMeanA')]
        dframe$foldChange<-1/dframe$foldChange
        dframe$log2FoldChange<- - dframe$log2FoldChange
        }
    else dframe=NULL
    return(dframe)
}
@

\section{ \deseq Similarity tests}

Functions to obtain p-values to test that two conditions give the same expression
to within a given factor.

<<>>=
nbinomTestSimilarity <- function(cds, condA, condB, maxratiovec = c(2) ){
    colA <- conditions(cds) == condA
    colB <- conditions(cds) == condB
    rawScvA <- fData(cds)[,paste('disp',dispTable(cds)[condA],sep='_')]
    rawScvB <- fData(cds)[,paste('disp',dispTable(cds)[condB],sep='_')]
    outdf <- data.frame( id = rownames(counts(cds)), stringsAsFactors=FALSE)
    for ( maxratio in maxratiovec) {
	pval1 <- nbinomTestForMatricesSimilarity( counts(cds)[,colA],
	    counts(cds)[,colB], sizeFactors(cds)[colA], sizeFactors(cds)[colB],
	    rawScvA, rawScvB, maxratio)
	pval2 <- nbinomTestForMatricesSimilarity( counts(cds)[,colB],
	    counts(cds)[,colA], sizeFactors(cds)[colB], sizeFactors(cds)[colA],
	    rawScvB, rawScvA, maxratio)
	# combine the p values as though the two tests are independent:
	pval <- 1 - (1- pval1) * (1-pval2)
	padj <- p.adjust( pval, method = 'BH')
	outdf[[ paste0('simpval_', as.character(maxratio)) ]] <- pval
	outdf[[ paste0('simpadj_', as.character(maxratio)) ]] <- padj
    }
    return( outdf )
}
@

<<>>=
nbinomTestForMatricesSimilarity <- function(countsA, countsB, 
    sizeFactorsA, sizeFactorsB, dispsA, dispsB, ABratio){
    
    kAs <- rowSums( cbind( countsA ))
    kBs <- rowSums( cbind( countsB ))
    mus <- rowMeans( cbind( t(t(countsA)/sizeFactorsA), t(t(countsB)/sizeFactorsB)))
    muBs <- mus*(sum(sizeFactorsA)+sum(sizeFactorsB)) /
	(ABratio * sum(sizeFactorsA) + sum(sizeFactorsB) )
    muAs <- ABratio * muBs
    fullVarsA <- pmax(
	muAs * sum(sizeFactorsA) + dispsA * muAs^2 * sum(sizeFactorsA^2),
	muAs * sum(sizeFactorsA) * (1 + 1e-08))
    fullVarsB <- pmax(
	muBs * sum(sizeFactorsB) + dispsB * muBs^2 * sum(sizeFactorsB^2),
	muBs * sum(sizeFactorsB) * (1 + 1e-08))
    sumDispsA <- (fullVarsA - muAs * sum(sizeFactorsA))/(muAs*sum(sizeFactorsA))^2
    sumDispsB <- (fullVarsB - muBs * sum(sizeFactorsB))/(muBs*sum(sizeFactorsB))^2
    
    testonegene <- function (i) {
	if (kAs[i] == 0 & kBs[i] == 0) 
	   return(NA) 
	ks <- 0:(kAs[i] + kBs[i])
	ps <- dnbinom(ks, mu = muAs[i]*sum(sizeFactorsA), size = 1/sumDispsA[i]) *
	    dnbinom( kAs[i] + kBs[i] - ks, mu = muBs[i]*sum(sizeFactorsB),
		size = 1/sumDispsB[i])
	pobs <- dnbinom(kAs[i], mu = muAs[i]*sum(sizeFactorsA), size = 1/sumDispsA[i]) *
	    dnbinom( kBs[i], mu = muBs[i]*sum(sizeFactorsB),
		size = 1/sumDispsB[i])
	stopifnot(pobs==ps[kAs[i] + 1])
	numer <- ps[1:(kAs[i] + 1)]
	return( sum(numer)/sum(ps) )
    }

    return( sapply(seq(along=kAs), testonegene))
}
@

<<>>=
f.loadsimtest <- function(condA,condB,nindex){
    ntable<-t(sapply(nindex,
                     FUN=function (x) c(paste0(x$condA,x$condB),
                     x$filename)))
    forward.name <- paste0(condA,condB)
    reverse.name <- paste0(condB,condA)
    if (forward.name %in% ntable[,1] ) 
        dframe <- read.delim(ntable[match(forward.name,ntable[,1]),2])
    else if (reverse.name %in% ntable[,1]) 
        dframe <- read.delim(ntable[match(reverse.name,ntable[,1]),2])
    else dframe = NULL
    return(dframe)
}
@

\section{Manipulating \deseq results}

First, a generic function for making a table in which each entry is the result
of applying some user function to each of the hypothesis test results
matrices described in an object like \texttt{nbinomindex}
<<>>=
f.summarize1v1 <- function( nbindex, countdataset, FUN = NULL){
    lconds <- levels(conditions(cds))
    summarymatrix <-
        array( data = 0, dim = replicate(2, length(lconds)),
          dimnames = replicate(2, lconds, simplify = FALSE))
    for (nbtest in nbindex) {
        dframe<-read.delim( nbtest$filename, header=TRUE)
        summarymatrix[ nbtest$condA, nbtest$condB] <- FUN(dframe)
     }
    return(summarymatrix)
}
@

A function we will often use to get the elements of an nbininomTest
data frame that are selected as significant as a particular False
Discovery Rate. The default FDR is 10\%.
<<>>=
f.meetsfdr <- function (x, fdr = 0.1) {
    meetsfdr<- x$padj < fdr
    meetsfdr[is.na(meetsfdr)]<-FALSE
    return(meetsfdr)
}
@

A related function, which simply counts the hits:
<<>>=
f.hitsatfdr <- function (x, fdr = 0.1) {
    sum( f.meetsfdr(x,fdr=fdr))
}
@

Some other simple utility functions:
<<>>=
f.isexpressed <- function (x) x$baseMean > 0
f.getlogbaseMean <- function (x) log10(x$baseMean)
@

\section{Visualizing \deseq results}

Function plots histograms of the (log10) baseMeans for every gene in
the gene universe and all the hits (in red), as well as the
log2foldchanges. The \texttt{regularizelog} is a small number added to
all baseMeans to ensure that they are positive prior to taking
log10.

<<>>=
f.plothitstats <- function(condA, condB, nindex, fdr=0.1, regularizelog=0.1,
                           logmeanbreaks="FD", log2foldbreaks="FD") {
    # Plots log2foldchange and baseMean hit and all ditributions
    dframe <- f.loadntest(condA,condB,nindex)
    hitlist <- which(dframe$padj<fdr)
    meanhist<-hist( log10(regularizelog + dframe$baseMean),
                   breaks=logmeanbreaks, main=paste0(condA,'vs',condB),
                   xlab='log10 baseMean express.', border=NA,col='black')
    hist( log10(regularizelog + dframe$baseMean[hitlist]),
         breaks=meanhist$breaks, col='red',add=TRUE,border=NA)
    foldhist<- hist( dframe$log2FoldChange,
                   breaks=log2foldbreaks, main=paste0(condA,'vs',condB),
                   xlab='log2FoldChange', border=NA, col='black',
                    xlim=c(-3,3))
    hist(dframe$log2FoldChange[hitlist], breaks=foldhist$breaks,
         col='red',add=TRUE, border=NA)
}
@

\subsection{Subsetting/displaying top hits"}

<<>>=
f.table_mostextreme <- function (dframe, nshow=10, ...) {
    biggest <- dframe[order(dframe$log2FoldChange,decreasing=TRUE)[1:nshow] ,
                      c("id","log2FoldChange","baseMean")]
    smallest <- dframe[order(dframe$log2FoldChange,decreasing=FALSE)[1:nshow] ,
                      c("id","log2FoldChange","baseMean")]
    names(biggest)<-c('Gene','log2Fold','MeanExpr')
    names(smallest)<-names(biggest)
    return( xtable( cbind(biggest, smallest), align="llcc|lcc", ... ))
    }
f.table_filteredextremes <- function(condA, condB, nindex, nshow=10,
                                     filterfunc= function (x) TRUE,
                                     label, caption, ...) {
    # filterfunc returns a logical used to index the rows of the dataframe
    dframe <- f.loadntest(condA,condB,nindex)
    dframe <- dframe[filterfunc(dframe),]
    xt <- f.table_mostextreme(dframe, nshow, caption=caption, label=label, ...)
    print(xt, caption.placement='top',include.rownames=FALSE, ...)
    }
@


\section{Functions for GO with goseq}

GOseq requires two vectors as input. First a general function that
conditions the output from any of our \deseq tests for the goseq pipeline
<<>>=
f.vectorsforgoseq <- function(condA, condB, nindex,
                              universefunc = function(x) rep(TRUE,dim(x)[1]),
                              isDEfunc = function(x) x$padj < 0.1,
                              biasfunc = function(x) NULL, ...) {
    # universefunc and isDEfunc should return logicals for every entry
    # in the DEseq results. biasfunc should return null or a numeric vector.
    dframe <- f.loadntest(condA,condB,nindex)
    isinuniverse <- universefunc(dframe)
    isDE <- isDEfunc(dframe)
    DEgenes <- isDE[isinuniverse]
    names(DEgenes) <- dframe$id[isinuniverse]
    bias.data <- biasfunc(dframe, ...)[isinuniverse]
    return( list(DEgenes=DEgenes, bias.data=bias.data) )
}
@

A function that will actually do the goseq testing.
<<>>=
f.goseqresults <- function( goseqvectors , genome='mm9', id='geneSymbol', ...) {
    pwf <- nullp(DEgenes = goseqvectors$DEgenes, genome=genome,
                 id=id, bias.data = goseqvectors$bias.data)
    GOdat<-goseq(pwf,genome=genome, id=id, ...)
    #GOdat$GOTERM<-sapply(mget(GOdat$category,GOTERM),function (x) x@Term)
    GOdat$GOTERM <- Term(GOdat$category)
    GOdat$over_padj<-p.adjust(GOdat$over_represented_pvalue,method="BH")
    GOdat$under_padj<-p.adjust(GOdat$under_represented_pvalue,method="BH")
    return(GOdat)
}
@

\section{RPKM conversion}

The code below is based on the code of the \deseq functions \texttt{nbinomTest}
and \texttt{nbinomTestForMatrices}.
<<>>=
f.getrpkmstats <- function(cds,cond,length_bases){
    # Assumes sizeFactors(cds) are millions of total reads
    col <- conditions(cds)==cond
    disps <- fData(cds)[, paste('disp',dispTable(cds)[cond],sep='_')]
    counts <- counts(cds)[, col]
    sizeFactors <- sizeFactors(cds)[col]
    mus <- rowMeans(t(t(counts)/sizeFactors))
    Varofmu <- mus* sum(1/sizeFactors)+disps*mus^2
    Varofmu <- Varofmu/sum(col)^2
    Sigofmu <- sqrt(Varofmu)
    rpkm <- mus / length_bases * 10^3
    Sigofrpkm <- Sigofmu /length_bases *10^3
    out<-data.frame(rpkm=rpkm,Sigofrpkm=Sigofrpkm)
    colnames(out)<-c('rpkm','rpkmstdev')
    return(out)
}
@

\section{ Multi bar plot with error bars }


The following function helps to reproduce something like the plots in
figures 1 an S1 of the Marks paper. Had to make my own function to
create a bar plot.
<<>>=
f.barplotwitherror <- function(height, dheight.neg = NULL,
                               dheight.plus = dheight.neg, horiz=FALSE, ...){
    #heith, dheight.neg, dheight.plus are data.frames or coerceable to matrices
    #Each row corresponds to say, a gene, and each column, say, to a condition.
    # The output will be a bar plot with black error bars height-neg, height+pos
    barpositions <- barplot(t(as.matrix(height)), horiz=horiz, beside=TRUE, ...)
    if (!(is.null(dheight.neg) && is.null(dheight.plus)) ){
        if (horiz==FALSE) {
            f.drawerrbar <- function (barpos, h, dh_n, dh_p) {
                segments(x0=barpos, y0= h-dh_n, y1= h+dh_p)
            }
        }
        else {
            f.drawerrbar <- function (barpos, h, dh_n, dh_p) {
                segments(y0=barpos, x0= h-dh_n, x1= h+dh_p)
            }
        }
        if (is.null(dheight.neg)) dheight.neg <- array(0,dim(dheight.plus))
        if (is.null(dheight.plus)) dheight.plus <- array(0,dim(dheight.neg))
        invisible( mapply(f.drawerrbar, barpositions,
                          t(as.matrix(height)),
                          t(as.matrix( dheight.neg)),
                          t(as.matrix( dheight.plus)))
                  )
    }
}
@

\section{Functions related to chunked BED data}

\subsection{few gene extraction}

A utility function to grab data for a vector of genes
\texttt{desiredlist}.
<<>>=
f.getFromPreprocBed <- function( desiredlist,  patternname, samplelist,
                                preprocdir ='./intermediate_results/'){
    covdata <- list()
    for (samplename in samplelist) {
        datafilefullpath <- paste0(preprocdir, patternname, '_', samplename)
        tempfile <- subsetProcessedFiles( desiredlist, datafilefullpath )
        covdata[[samplename]] <- getDataFromCovTemp(tempfile)
    }
    return(covdata)
}
@

A covdata object made by \texttt{f.getFromPreprocBed} can be plotted
with the function below:

<<>>=
f.plotselectedCovs <- function( covdata, x = seq.int(-10000,9999,10),
                               xlab = 'bp-TSS'){
    par(mfrow=c( length(covdata), length(rownames(covdata[[1]]))))
    par(mar = c(2, 4, 2, 1))
    for (s in seq(along = names(covdata))) {
        sname <- names(covdata)[s]
        for (i in seq(along = rownames(covdata[[sname]]))) {
            id <- rownames(covdata[[sname]])[i]
            plot( x, covdata[[sname]][id,], type='l',
                 main = ifelse( s == 1, id, ''),
                 xlab = ifelse( s == length(covdata), xlab, ''),
                 ylab = ifelse( i == 1, sname, '')
                 )
        }
    }
}
@

\subsection{Unweighted gene subset averaging}

Function to get the the average coverages for multiple genesubsets and
chIP datasets:

<<>>=
f.avgFromPreprocBed <- function( gs_list,  patternname, samplelist,
                                preprocdir ='./intermediate_results/'){
    x <- list()
    for (samplename in samplelist) {
        message(paste('Processing', samplename))
        datafilefullpath <- paste0(preprocdir, patternname, '_', samplename)
        covdata <- sumCoverageBatch( gs_list, datafilefullpath )
        for (i in seq(along=gs_list)) {
            x[[samplename]][[i]] <-  covdata$sumcovs[[i]] /
                length( covdata$genessummed[[i]] )
        }
        names(x[[samplename]]) <- names(gs_list)
    }
    return(x)
}
@

<<>>=
f.avgFromPreprocBed_old <- function( gs_list,  patternname, samplelist,
                                preprocdir ='./intermediate_results/'){
    x <- list()
    for (samplename in samplelist) {
        message(paste('Processing', samplename))
        x[[samplename]]<-list()
        for (s in seq(along = gs_list)) {
            datafilefullpath <- paste0(preprocdir, patternname, '_', samplename)
            tempfile <- subsetProcessedFiles( gs_list[[s]], datafilefullpath )
            x[[samplename]][[names(gs_list)[s]]] <-
                sumCoverageFromTemp(tempfile)/length(gs_list[[s]])
            unlink( tempfile )
        }
    }
    return(x)
}
@

\subsection{Creating an intensity-weighted control for average ChIP coverage}


<<>>=
library(MASS)
library(caTools)
f.chipControlWeights <- function( gene_intensity , genesubset, plotresults = FALSE,
                                 windowtoavg = 51) {
    gene_rank <- rank(gene_intensity, ties.method = "random" )
    fitparams <- fitdistr(gene_intensity[genesubset], 'log-normal')
    fitparams <- fitparams$estimate
    if (plotresults) {
        plot.ecdf( log10(gene_intensity[genesubset]), xlim=c(-3,3),
                  xlab = 'log10 Intensity',ylab='CDF',main='chipControl')
        lines( seq(-3,3,0.1), plnorm(10^seq(-3,3,0.1),
                                     fitparams[1],fitparams[2]),lty=3)
    }
    fittedcdf <- plnorm(gene_intensity, fitparams[1], fitparams[2])
    gene_weight <- gene_intensity # Initialize. Will replace values soon.
    gene_weight[ order(gene_rank) ] <- diff( c( 0, fittedcdf[ order(gene_rank)]) )
    # Smooth the weights with a moving window average
    gene_weight[ order(gene_rank) ] <- caTools::runmean(
                                                gene_weight[ order(gene_rank) ],
                                                k= windowtoavg, endrule = 'mean')
    return(gene_weight)
}
@

This function runs a batch of gene lists and sample data:

<<>>=
f.controlFromPreprocBed <- function( gs_list, gene_intensity,
                                    patternname, samplelist,
                                    preprocdir ='./intermediate_results/'){
    # Function assumes that gene_intensity has names (the gene names)
    genenames <- names(gene_intensity)
    x <- list()
    for (samplename in samplelist) {
        message(paste('Processing', samplename))
        datafilefullpath <- paste0(preprocdir, patternname, '_', samplename)
        weights_list <- lapply(gs_list, function (x)
                               f.chipControlWeights( gene_intensity, x))
        x[[samplename]] <-
            weightedAvgCovBatch( datafilefullpath, weights_list, genenames)
    }
    return(x)
}
@

<<>>=
f.controlFromPreprocBed_old <- function( gs_list, gene_intensity,
                                    patternname, samplelist,
                                    preprocdir ='./intermediate_results/'){
    # Function assumes that gene_intensity has names (the gene names)
    genenames <- names(gene_intensity)
    x <- list()
    for (samplename in samplelist) {
        x[[samplename]]<-list()
        for (s in seq(along = gs_list)) {
            message(paste('Processing', samplename,names(gs_list)[s]))
            datafilefullpath <- paste0(preprocdir, patternname, '_', samplename)
            tempfile <- subsetProcessedFiles( genenames, datafilefullpath )
            weights <- f.chipControlWeights( gene_intensity, gs_list[[s]] )
            x[[samplename]][[names(gs_list)[s]]] <-
                weightedAvgCovFromTemp( tempfile, weights, genenames)
        }
    }
    return(x)
}
@

\subsection{Displaying average coverage}

A helper function for plotting the coverages and coverage controls
<<>>=
f.plotavgCovs <- function( covdata, covdatacontrol, ylims = NULL,
                          x = seq.int(-10000,9999,10), xlab = 'bp-TSS'){
    par(mfrow=c( length(covdata), length(names(covdata[[1]])) ) )
    par(mar = c(2, 4, 2, 1))
    for (s in seq(along = names(covdata))) {
        sname <- names(covdata)[s]
        for (i in seq(along = names(covdata[[sname]])) ) {
            id <- names(covdata[[sname]])[i]
            plot( x, covdata[[sname]][[id]], type='l',
                 main = ifelse( s == 1, id, ''),
                 xlab = ifelse( s == length(covdata), xlab, ''),
                 ylab = ifelse( i == 1, sname, ''),
                 ylim = c( 0, ifelse( is.null( ylims[[sname]]),
                 1.5*max(covdata[[sname]][[id]]), ylims[[sname]])),
                 col ='red'
                 )
            lines( x, covdatacontrol[[sname]][[id]], type='l', lty=2, col='black')
        }
    }
}
@

\subsection{ Statistics with Histone data }

Given weights $w$ and measurements $Y$, construct an empircal cdf for $Y$.
<<>>=
f.weightedcdf <- function( weights, Yvalues ) {
	# arguments must be vectors with names. 
	commonnames <- intersect(names(weights),names(Yvalues))
	w <- weights[commonnames]
	Y <- Yvalues[commonnames] 
	w <- w/sum(w);
	sortorder <- order(Y);
	return( data.frame( val = Y[sortorder], cdf.atval = cumsum( w[sortorder])))
}
@




\section{Correlation with Transcription factor ChIP binding data}

Function will plot a series of histograms
<<>>=
f.plotTFcdfs <- function(tf, tf_datacolumns = colnames(tf), genes.in.red, genes.in.blue, ...){
    for (tfname in tf_datacolumns) {
        plot.ecdf(tf[,tfname], col = 'black', do.points = FALSE,
                  main = tfname, ylab = 'cdf', ...)
        plot.ecdf(tf[genes.in.red , tfname], col ='red',
                  do.points = FALSE, add = TRUE)
        plot.ecdf(tf[genes.in.blue , tfname], col = 'blue',
                  do.points = FALSE, add = TRUE)
    }
}
@


\section{Sorting VS Differentiation plotting utilities}

Design: want a way of plotting the principal axes of our data:
ALL vs DIFF and GFP vs NEG on a single plot, overlayed with a 
qualification of those points. 

As in prior parts of my analysis, there may be a filter, 
and after that, there can be a function that takes
the remaining data frame and determines colors or point
properties in some way. It may be possible to have these
feed in arguments to a plot function using \verb+do.call+



\section{Utilities for melt/cast}


<<>>=
f.fixedcolsplit <- function(string, pattern, names){
    require(stringr)
    outputstr <- list()
    for (i in seq(along = names)){
    	matchpos <- regexpr( pattern = pattern, string, fixed=TRUE )
	outputstr[[i]] <- ifelse( matchpos != -1,
	    substr(string, start = 1, stop = matchpos -1), string)
	string <- ifelse( matchpos != -1, 
	    str_sub(string, start = matchpos + 1), '')
    }
    names(outputstr) <- names
    outputstr[['stringsAsFactors']] = FALSE
    do.call( data.frame, outputstr)
}
@

Takes a data frame x, splits by the specified column name according to pattern,
and gives the new columns the names given by names. If a name is a pre-existing,
it is overwritten. The data frame with new columns appended is returned,
<<>>=
f.colsplitandmerge <- function( x, coltosplit, pattern, names) {
    strtosplit <- x[,coltosplit]
    splitcols <- f.fixedcolsplit( strtosplit, pattern, names)
    outdf <- x
    for (nm in names){
	outdf[[nm]] <- splitcols[[nm]]
    }
    return(outdf)
}
@

<<>>=
f.previewmelted <- function( melteddata){ 
    lapply( split( melteddata[,c('meta','variable')], 
	    melteddata$source, drop = TRUE), table)	
}
@

<<>>=
f.subsetmelted <- function( m.data, subsetlist) {
    rowstokeep.overall <- rep(FALSE, length(m.data[,1]))
    for (slist in subsetlist){
	rowstokeep <- rep(TRUE, length(rowstokeep.overall))
	for (varname in names(slist)){
	    rowstokeep <- rowstokeep & (m.data[,varname] %in% slist[[varname]])
	}
	rowstokeep.overall <- rowstokeep.overall | rowstokeep
    }
    return( m.data[rowstokeep.overall,] )
}
@

<<>>=
f.quantXcat_melted <- function( quantdata, catdata) {
    outdat <- dlply( catdata, 'meta', function(x) 
    	subset(quantdata, quantdata[,'GeneSymbol'] %in% x$value))
    idcols <- names(quantdata)
    idcols <- idcols[ idcols != 'value' ]
    outdf <-melt( outdat, id = idcols)
    if (is.factor(catdata$value)) {
	outdf$GeneSymbol <- factor( outdf$GeneSymbol, levels(catdata$value))
    }
    if (is.factor(catdata$meta)) {
	outdf$L1 <- factor(outdf$L1, levels(catdata$meta))
    }
    return(outdf)
}
@

<<>>=
f.addunitbox <- function() {
    boxdata <- data.frame( xs = c(1,1,-1,-1,1), ys = c(1,-1,-1,1,1))
    geom_path( data=boxdata, aes(x=xs,y=ys,fill=NULL,shape=NULL),color='black')
}
@


\section{String manipulation}

<<>>=
f.simpleCap <- function(x) {
    s <- strsplit(x, " ")[[1]]
        paste(toupper(substring(s, 1,1)), substring(s, 2),
	          sep="", collapse=" ")
		  }
@
